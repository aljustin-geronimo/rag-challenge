{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0a80e2",
   "metadata": {},
   "source": [
    "# PDF Text + Graphical Data Q&A\n",
    "\n",
    "This notebook documents the approach and demonstrates results for:\n",
    "\n",
    "- Extracting **text** and **graphical data** (tables, basic bar charts) from a PDF.\n",
    "- Converting those into structured, queryable data.\n",
    "- Letting users **ask questions** against both text and derived data.\n",
    "\n",
    "**Instructions:** Place your PDF under `../data/` and set its filename below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "OUTPUTS = Path(\"../outputs\")\n",
    "OUTPUTS.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# <<< SET YOUR PDF FILE HERE >>>\n",
    "PDF_FILE = DATA_DIR / \"sample.pdf\"  # replace after uploading\n",
    "assert PDF_FILE.exists(), f\"PDF not found: {PDF_FILE}. Put your PDF under {DATA_DIR}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37879a5c",
   "metadata": {},
   "source": [
    "## 1) Extraction\n",
    "We use:\n",
    "- `pdfplumber` for text and page rasterization.\n",
    "- `camelot` (stream/lattice) → `tabula-py` → `pdfplumber` fallback for tables.\n",
    "- Simple computer vision + OCR to attempt digitizing **bar charts**.\n",
    "\n",
    "> Note: Chart digitization is best-effort. Tables are the primary path to precise structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fe500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.extract_text import extract_text\n",
    "from src.extract_tables import extract_tables\n",
    "from src.extract_charts import extract_charts_as_data\n",
    "\n",
    "pages = extract_text(str(PDF_FILE))\n",
    "tables = extract_tables(str(PDF_FILE), flavor=\"stream\")\n",
    "chart_dfs, chart_images = extract_charts_as_data(str(PDF_FILE), str(OUTPUTS/\"images\"))\n",
    "\n",
    "len(pages), len(tables), len(chart_dfs), len(chart_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ecf56",
   "metadata": {},
   "source": [
    "### Quick Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ce766",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0].text[:1000] if pages else \"(no text)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].head() if tables else \"(no tables)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_dfs[0].head() if chart_dfs else \"(no chart data detected)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc77fb",
   "metadata": {},
   "source": [
    "## 2) Build Searchable Index for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aeb662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.build_index import build_text_index, TextChunk, tables_summary\n",
    "import os\n",
    "\n",
    "model_name = os.getenv(\"EMBEDDING_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "chunks = [TextChunk(page_num=p.page_num, text=p.text) for p in pages if p.text.strip()]\n",
    "text_index = build_text_index(chunks, model_name=model_name)\n",
    "\n",
    "print(\"Text chunks:\", len(chunks))\n",
    "tables_summary(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7b3d9",
   "metadata": {},
   "source": [
    "## 3) Ask Questions\n",
    "We support:\n",
    "- **Semantic text search** over the narrative text.\n",
    "- **Table/derived data queries** for simple aggregations and previews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5467a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.qa import answer_text_query, answer_table_query\n",
    "\n",
    "q1 = \"What does the document say about revenue growth?\"\n",
    "ans1 = answer_text_query(text_index, q1, top_k=int(os.getenv(\"TOP_K\", 5)))\n",
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"sum of Revenue where Year == 2023\"\n",
    "ans2 = answer_table_query(tables + chart_dfs, q2)\n",
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562b9f4",
   "metadata": {},
   "source": [
    "## 4) Notes on Design Choices & Challenges\n",
    "\n",
    "1. **Multi-backend table extraction**: PDFs vary widely. We layer Camelot → Tabula → pdfplumber to maximize table recovery.\n",
    "2. **Chart digitization (best-effort)**: Simple bar charts can often be parsed by detecting vertical rectangles and scaling bar heights. Arbitary plots (line charts, stacked bars, complex legends) are left as future work.\n",
    "3. **Embeddings**: We use local Sentence-Transformers to avoid external APIs. Cosine similarity over normalized vectors provides robust semantic search across pages.\n",
    "4. **NL-to-table**: A tiny pattern parser recognizes queries like `sum of <col> where <col2> == X`. When unrecognized, we surface a **preview** of likely columns as a helpful fallback.\n",
    "5. **Provenance**: We retain page numbers with text chunks, and we keep DataFrames for tables so you can trace results back to source pages.\n",
    "\n",
    "**Limitations**\n",
    "- Tabula requires Java; if missing, those steps are skipped.\n",
    "- Ghostscript improves Camelot lattice detection.\n",
    "- Chart digitization is intentionally conservative: it will skip when uncertain rather than hallucinate numbers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
